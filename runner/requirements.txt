#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile requirements.in
#
accelerate==1.0.1
    # via
    #   -r requirements.in
    #   peft
aiohappyeyeballs==2.4.3
    # via aiohttp
aiohttp==3.10.10
    # via
    #   datasets
    #   fsspec
    #   vllm
aiosignal==1.3.1
    # via
    #   aiohttp
    #   ray
annotated-types==0.7.0
    # via pydantic
anyio==4.6.2.post1
    # via
    #   httpx
    #   openai
    #   starlette
    #   watchfiles
attrs==24.2.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
av==13.1.0
    # via -r requirements.in
bitsandbytes==0.44.1
    # via -r requirements.in
certifi==2024.8.30
    # via
    #   httpcore
    #   httpx
    #   requests
charset-normalizer==3.4.0
    # via requests
click==8.1.7
    # via
    #   ray
    #   uvicorn
cloudpickle==3.1.0
    # via outlines
datasets==3.0.1
    # via outlines
deepcache==0.1.1
    # via -r requirements.in
diffusers==0.30.3
    # via
    #   -r requirements.in
    #   deepcache
dill==0.3.8
    # via
    #   datasets
    #   multiprocess
diskcache==5.6.3
    # via outlines
distro==1.9.0
    # via openai
einops==0.8.0
    # via vllm
fastapi==0.115.2
    # via
    #   -r requirements.in
    #   vllm
filelock==3.16.1
    # via
    #   datasets
    #   diffusers
    #   huggingface-hub
    #   ray
    #   torch
    #   transformers
    #   triton
    #   vllm
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
    #   ray
fsspec[http]==2024.6.1
    # via
    #   datasets
    #   huggingface-hub
    #   torch
gguf==0.10.0
    # via vllm
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
httpcore==1.0.6
    # via httpx
httptools==0.6.4
    # via uvicorn
httpx==0.27.2
    # via openai
huggingface-hub==0.25.2
    # via
    #   -r requirements.in
    #   accelerate
    #   datasets
    #   diffusers
    #   peft
    #   tokenizers
    #   transformers
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
importlib-metadata==8.5.0
    # via
    #   diffusers
    #   vllm
interegular==0.3.3
    # via
    #   lm-format-enforcer
    #   outlines
jinja2==3.1.4
    # via
    #   outlines
    #   torch
jiter==0.6.1
    # via openai
jsonschema==4.23.0
    # via
    #   mistral-common
    #   outlines
    #   ray
jsonschema-specifications==2024.10.1
    # via jsonschema
lark==1.2.2
    # via outlines
llvmlite==0.43.0
    # via numba
lm-format-enforcer==0.10.6
    # via vllm
markupsafe==3.0.1
    # via jinja2
mistral-common[opencv]==1.4.4
    # via vllm
mpmath==1.3.0
    # via sympy
msgpack==1.1.0
    # via ray
msgspec==0.18.6
    # via vllm
multidict==6.1.0
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via datasets
nest-asyncio==1.6.0
    # via outlines
networkx==3.4.1
    # via torch
numba==0.60.0
    # via outlines
numpy==1.26.4
    # via
    #   -r requirements.in
    #   accelerate
    #   bitsandbytes
    #   datasets
    #   diffusers
    #   gguf
    #   mistral-common
    #   numba
    #   opencv-python-headless
    #   outlines
    #   pandas
    #   peft
    #   pyarrow
    #   scipy
    #   torchvision
    #   transformers
    #   vllm
    #   xformers
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-ml-py==12.560.30
    # via vllm
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.6.77
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
openai==1.51.2
    # via vllm
opencv-python-headless==4.10.0.84
    # via mistral-common
outlines==0.0.46
    # via vllm
packaging==24.1
    # via
    #   accelerate
    #   datasets
    #   huggingface-hub
    #   lm-format-enforcer
    #   peft
    #   ray
    #   transformers
pandas==2.2.3
    # via datasets
partial-json-parser==0.2.1.1.post4
    # via vllm
peft==0.13.2
    # via -r requirements.in
pillow==10.4.0
    # via
    #   -r requirements.in
    #   diffusers
    #   mistral-common
    #   torchvision
    #   vllm
prometheus-client==0.21.0
    # via
    #   prometheus-fastapi-instrumentator
    #   vllm
prometheus-fastapi-instrumentator==7.0.0
    # via vllm
propcache==0.2.0
    # via yarl
protobuf==5.28.2
    # via
    #   -r requirements.in
    #   ray
    #   vllm
psutil==6.0.0
    # via
    #   -r requirements.in
    #   accelerate
    #   peft
    #   vllm
py-cpuinfo==9.0.0
    # via vllm
pyairports==2.1.1
    # via outlines
pyarrow==17.0.0
    # via datasets
pycountry==24.6.1
    # via outlines
pydantic==2.9.2
    # via
    #   -r requirements.in
    #   fastapi
    #   lm-format-enforcer
    #   mistral-common
    #   openai
    #   outlines
    #   vllm
pydantic-core==2.23.4
    # via pydantic
python-dateutil==2.9.0.post0
    # via pandas
python-dotenv==1.0.1
    # via uvicorn
python-multipart==0.0.12
    # via -r requirements.in
pytz==2024.2
    # via pandas
pyyaml==6.0.2
    # via
    #   accelerate
    #   datasets
    #   gguf
    #   huggingface-hub
    #   lm-format-enforcer
    #   peft
    #   ray
    #   transformers
    #   uvicorn
    #   vllm
pyzmq==26.2.0
    # via vllm
ray==2.37.0
    # via vllm
referencing==0.35.1
    # via
    #   jsonschema
    #   jsonschema-specifications
    #   outlines
regex==2024.9.11
    # via
    #   diffusers
    #   tiktoken
    #   transformers
requests==2.32.3
    # via
    #   datasets
    #   diffusers
    #   huggingface-hub
    #   mistral-common
    #   outlines
    #   ray
    #   tiktoken
    #   transformers
    #   vllm
rpds-py==0.20.0
    # via
    #   jsonschema
    #   referencing
safetensors==0.4.5
    # via
    #   -r requirements.in
    #   accelerate
    #   diffusers
    #   peft
    #   transformers
scipy==1.14.1
    # via -r requirements.in
sentencepiece==0.2.0
    # via
    #   -r requirements.in
    #   mistral-common
    #   vllm
six==1.16.0
    # via python-dateutil
sniffio==1.3.1
    # via
    #   anyio
    #   httpx
    #   openai
starlette==0.40.0
    # via
    #   fastapi
    #   prometheus-fastapi-instrumentator
sympy==1.13.3
    # via torch
tiktoken==0.7.0
    # via
    #   mistral-common
    #   vllm
tokenizers==0.20.1
    # via
    #   transformers
    #   vllm
torch==2.4.0
    # via
    #   accelerate
    #   bitsandbytes
    #   deepcache
    #   peft
    #   torchvision
    #   vllm
    #   xformers
torchvision==0.19.0
    # via vllm
tqdm==4.66.5
    # via
    #   datasets
    #   gguf
    #   huggingface-hub
    #   openai
    #   outlines
    #   peft
    #   transformers
    #   vllm
transformers==4.45.2
    # via
    #   -r requirements.in
    #   deepcache
    #   peft
    #   vllm
triton==3.0.0
    # via
    #   -r requirements.in
    #   torch
typing-extensions==4.12.2
    # via
    #   fastapi
    #   huggingface-hub
    #   mistral-common
    #   openai
    #   outlines
    #   pydantic
    #   pydantic-core
    #   torch
    #   vllm
tzdata==2024.2
    # via pandas
urllib3==2.2.3
    # via requests
uvicorn[standard]==0.32.0
    # via
    #   -r requirements.in
    #   vllm
uvloop==0.21.0
    # via uvicorn
vllm==0.6.3
    # via -r requirements.in
watchfiles==0.24.0
    # via uvicorn
websockets==13.1
    # via uvicorn
xformers==0.0.27.post2
    # via
    #   -r requirements.in
    #   vllm
xxhash==3.5.0
    # via datasets
yarl==1.15.4
    # via aiohttp
zipp==3.20.2
    # via importlib-metadata
